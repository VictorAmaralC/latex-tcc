\chapter[Desenvolvimento dos modelos de treinamento]{Desenvolvimento dos modelos de treinamento}
\addcontentsline{toc}{chapter}{Desenvolvimento dos modelos de treinamento}
\label{chap:desenvolvimento}

O problema central que o modelo de aprendizado federado busca resolver reside na exposição potencial de dados sensíveis quando centralizados em um único servidor para treinamento de modelos de IA. Em vez de enviar os dados dos dispositivos para um servidor central, onde poderiam ser acessados ou comprometidos, o aprendizado federado propõe um paradigma descentralizado no qual os dispositivos realizam o treinamento localmente, compartilhando apenas os parâmetros do modelo (como pesos e gradientes) com o servidor central. Esta abordagem permite que os dispositivos colaborem no desenvolvimento de um modelo global sem nunca expor os dados locais. 

A estruturação do problema foi conduzida considerando-se um cenário prático, onde múltiplos dispositivos, cada um contendo dados não identicamente distribuídos (não-IID), contribuem para o treinamento de um modelo de classificação de imagens (utilizando o conjunto de dados Fashion-MNIST como referência). Este cenário foi escolhido por refletir uma situação comum em aplicações reais, onde dados como registros de saúde, preferências de usuários ou informações financeiras são distribuídos entre dispositivos pessoais e não podem ser compartilhados diretamente por questões de privacidade e conformidade com regulamentos como o GDPR. Assim, o método desenvolvido abrange a implementação de um modelo federado que deve ser capaz de aprender de maneira eficiente e precisa a partir de dados dispersos, preservando a privacidade, e enfrenta desafios como a heterogeneidade dos dispositivos, a variabilidade da conectividade de rede e a necessidade de garantir a convergência do modelo global. A escolha do aprendizado federado, mais especificamente do processo Federated Averaging (FedAvg), é justificada pela sua capacidade de operar eficientemente em ambientes com essas características, buscando balancear a necessidade de proteção dos dados com a performance do modelo treinado.

\section{Implementação do Modelo de Aprendizado Federado}

Para melhor entendimento, foi dividido em seções a implementação do código do modelo de aprendizado federado. Cada seção abordará uma etapa do desenvolvimento do modelo e por fim será apresentado o código completo.

\subsection{Definição do Modelo Keras}

O primeiro passo na implementação do modelo federado foi a criação de um modelo Keras básico, que servirá como base para o treinamento federado. O modelo foi projetado para a base de dados Fashion-MNIST, que contém imagens de roupas divididas em 10 classes. A estrutura escolhida para esse modelo é uma Convolutional Neural Network (CNN), que é ideal para processar imagens. A CNN foi configurada com duas camadas de convolução seguidas por camadas de pooling, um padrão comum em tarefas de classificação de imagens, pois essas camadas são muito eficazes na extração de características visuais. A última parte do modelo é uma camada densa com 128 neurônios e a camada de saída com 10 neurônios, correspondendo às classes da base de dados.

\begin{lstlisting}[language=Python, caption={Função para criar um modelo Keras}, label={lst:create_keras_model}]
    def create_keras_model():
        model = tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28, 1)),
            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])
        return model
\end{lstlisting}
    
A escolha de uma CNN foi feita devido ao seu ótimo desempenho em tarefas de visão computacional, como é o caso do Fashion-MNIST, onde características como bordas, texturas e padrões podem ser capturados e processados de forma eficiente pelas camadas convolucionais.

\subsection{Construção do Modelo Federado}

Uma escolha importante ao implementar um modelo federado é como serão avaliadas as métricas de desempenho. Além da acurácia tradicional (\textit{Sparse Categorical Accuracy}), foi adicionada a métrica de Acurácia \textit{Top-3} (\textit{Sparse Top-K Categorical Accuracy}), que avalia se a classe correta está entre as três previsões mais prováveis feitas pelo modelo. Essa escolha é interessante em contextos onde o erro de classificação é aceitável se a previsão correta estiver próxima do topo, o que pode ser útil em sistemas de recomendação ou em ambientes onde há muitas classes e as previsões precisam ser refinadas ao longo do tempo.

\begin{lstlisting}[language=Python, caption={Construção do modelo federado}, label={lst:build_federated_model}]
    def create_federated_model():
    keras_model = create_keras_model()

    return tff.learning.models.from_keras_model(
        keras_model,
        input_spec=(tf.TensorSpec(shape=[None, 28, 28, 1], 
                        dtype=tf.float32),
                    tf.TensorSpec(shape=[None], dtype=tf.int64)),
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        metrics=[
            tf.keras.metrics.SparseCategoricalAccuracy(),
            tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)
        ]
    )
\end{lstlisting}

Ao incluir essa métrica no modelo federado, a expectativa era observar uma melhora no desempenho geral ao lidar com a base de dados distribuída, onde as variabilidades dos dados entre os dispositivos podem dificultar a obtenção de acurácia elevada de imediato. A Acurácia Top-3 oferece uma margem para avaliar se o modelo está capturando informações corretas em um cenário mais flexível.

\subsection{Construção do Processo de Federado}

O processo federado foi implementado utilizando o algoritmo Federated Averaging, que combina os pesos atualizados de cada cliente em um servidor central, onde os modelos locais são treinados nos dados locais e suas atualizações são agregadas. A escolha do Federated Averaging se deve à sua eficiência e simplicidade, especialmente ao lidar com grandes quantidades de dados distribuídos. Além disso, ele permite que os dispositivos participantes treinem seus modelos localmente e compartilhem apenas os gradientes ou atualizações dos pesos, preservando assim a privacidade dos dados dos usuários.

\begin{lstlisting}[language=Python, caption={Construção do processo federado}, label={lst:build_federated_process}]
    def build_federated_averaging_process():
        return tff.learning.algorithms.build_unweighted_fed_avg(
            model_fn=create_federated_model,
            client_optimizer_fn=lambda: 
                tf.keras.optimizers.Adam(learning_rate=0.001),
            server_optimizer_fn=lambda: 
                tf.keras.optimizers.SGD(learning_rate=1.0)
    )
\end{lstlisting}

Foi utilizado o otimizador Adam nos dispositivos locais, uma escolha feita para lidar melhor com as variações nos dados entre diferentes dispositivos, já que o Adam tem uma capacidade adaptativa de ajustar a taxa de aprendizado com base nas características dos dados. O otimizador SGD foi usado no servidor para combinar as atualizações dos modelos, garantindo uma convergência mais estável.

\subsection{Preparação dos Dados}

A etapa de preparação dos dados é crítica em um modelo federado. Aqui, os dados foram normalizados e divididos entre 10 clientes, simulando diferentes dispositivos locais. Essa divisão é importante para simular um ambiente federado realista, onde diferentes dispositivos possuem subconjuntos dos dados totais e, portanto, variabilidades nas distribuições de dados.

\begin{lstlisting}[language=Python, caption={Preparação dos dados}, label={lst:data_preparation}]
    def preprocess(dataset):
        return dataset.map(lambda x, y: 
            (tf.cast(tf.expand_dims(x, -1), tf.float32), 
             tf.cast(y, tf.int64))).batch(20)

    def create_client_data(images, labels, num_clients=10, 
            num_samples_per_client=6000):
        client_data = []
        for i in range(num_clients):
            client_images = 
                images[i*num_samples_per_client:(i+1)*
                        num_samples_per_client]
            client_labels = 
                labels[i*num_samples_per_client:(i+1)*
                        num_samples_per_client]
            dataset = 
                tf.data.Dataset.from_tensor_slices(
                    (client_images, client_labels))

            client_data.append(preprocess(dataset))
        return client_data
\end{lstlisting}

A escolha da base de dados Fashion-MNIST foi feita pela simplicidade e familiaridade desse conjunto no treinamento de modelos de classificação de imagens. Ele oferece um bom balanço entre complexidade visual e tamanho, sendo leve o suficiente para ser usado em dispositivos locais sem grandes recursos computacionais.

\subsection{Treinamento do Modelo Federado}

\begin{lstlisting}[language=Python, caption={Treinamento do modelo federado}, label={lst:federated_training}]
    iterative_process = build_federated_averaging_process()
    state = iterative_process.initialize()

    for round_num in range(1, 21):
        state, metrics = 
            iterative_process.next(state, federated_train_data)
        print(f'Rodada {round_num}: {metrics}')
\end{lstlisting}

O treinamento é executado através de um processo iterativo, onde o modelo é treinado em múltiplas rodadas. A escolha de 20 rodadas de treinamento permite uma observação inicial do comportamento do modelo federado sem sobrecarregar o sistema. Em cada rodada, os clientes locais treinam o modelo com seus dados privados e enviam as atualizações para o servidor central, onde as atualizações são agregadas para formar um modelo global atualizado. O uso da função \texttt{next} no TensorFlow Federated aplica a agregação de \textit{FedAvg}, onde as médias das atualizações dos clientes são calculadas. O feedback das métricas de cada rodada permite acompanhar a evolução do modelo, especialmente em termos de precisão (via \textit{SparseCategoricalAccuracy}), oferecendo uma visão clara de como o modelo está se ajustando aos dados federados ao longo do tempo.

\section{Implementação do Modelo de Aprendizado Centralizado}

Para criar um modelo de treinamento centralizado, foi realizado um processo semelhante ao do aprendizado federado utilizando a mesma biblioteca de dados (MNIST) e as mesmas ferramentas, apenas sem a distribuição de dados entre dispositivos. Esse modelo será utilizado para comparação com o modelo federado desenvolvido anteriormente, possibilitando a avaliação do impacto do aprendizado centralizado versus o aprendizado federado na preservação da privacidade e desempenho.

\subsection{Criação do Modelo de Aprendizado Centralizado - CNN}

Neste projeto foram implementados 3 modelos de treinamento centralizado, sendo eles uma Rede Neural Convolucional (CNN), uma Rede Neural Recorrente (RNN) e um modelo Rede neural multicamadas (MLP). A seguir, será apresentado o código referente à implementação do modelo de CNN centralizado afim de ilustrar como funciona o treinamento centralizado. Ao final do capítulo, será apresentado o código completo dos 3 modelos com uma breve explicação de cada um.

\subsubsection{Definição do Modelo Keras}

\begin{lstlisting}[language=Python, caption={Definição do modelo Keras centralizado}, label={lst:centralized_keras_model}]
    def create_cnn_model():
    return tf.keras.models.Sequential([
        tf.keras.layers.Input(shape=(28, 28, 1)),
        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), 
            activation='relu'),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), 
            activation='relu'),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
\end{lstlisting}

Comparando com o modelo federado, a estrutura básica do modelo é a mesma, mas no federado, a criação do modelo é encapsulada em uma função TFF para suportar o treinamento distribuído, e o modelo não é compilado no momento da criação. O modelo centralizado é mais direto e é compilado imediatamente, o que simplifica a implementação.

\subsubsection{Carregamento e Preparação dos Dados}

\begin{lstlisting}[language=Python, caption={Carregamento e preparação dos dados centralizados}, label={lst:centralized_data}]
    (mnist_train, mnist_train_labels), 
    (mnist_test, mnist_test_labels) = 
        tf.keras.datasets.mnist.load_data()

    mnist_train = mnist_train / 255.0
    mnist_test = mnist_test / 255.0
    mnist_train = mnist_train[..., tf.newaxis].astype('float32')
    mnist_test = mnist_test[..., tf.newaxis].astype('float32')
\end{lstlisting}

Comparado ao modelo federado, o modelo centralizado lida com dados de forma mais direta e monolítica. No modelo federado, os dados são distribuídos entre os clientes e processados em batches menores para simular um cenário de aprendizado distribuído.

\subsubsection{Criação e Compilação do Modelo Centralizado}

\begin{lstlisting}[language=Python, caption={Criação e compilação do modelo centralizado}, label={lst:centralized_model}]
    model_cnn = create_cnn_model()
    model_cnn.compile(optimizer='adam',
                    loss='sparse_categorical_crossentropy',
                    metrics=['accuracy'])
\end{lstlisting}

No modelo federado, a compilação não ocorre na função de criação do modelo. Em vez disso, é feita na configuração do processo de treinamento, onde funções de perda e métricas são especificadas no contexto federado.

\subsubsection{Treinamento do Modelo Centralizado}

\begin{lstlisting}[language=Python, caption={Treinamento do modelo centralizado}, label={lst:centralized_training}]
    history_cnn = 
        model_cnn.fit(mnist_train, mnist_train_labels,
                        epochs=5, batch_size=32,
                        validation_data=
                            (mnist_test, mnist_test_labels))
\end{lstlisting}

No modelo federado, o treinamento é distribuído entre vários clientes e o processo de treinamento é coordenado centralmente. A atualização dos pesos é feita de maneira agregada, o que é uma abordagem fundamentalmente diferente da atualização direta utilizada no treinamento centralizado.

\subsubsection{Avaliação do Modelo}

\begin{lstlisting}[language=Python, caption={Avaliação do modelo centralizado}, label={lst:centralized_evaluation}]
    test_loss_cnn, test_acc_cnn = 
        model_cnn.evaluate(mnist_test, mnist_test_labels)
\end{lstlisting}

A avaliação do modelo é feita usando \texttt{model.evaluate()}, que calcula a perda e a precisão do modelo nos dados de teste. Isso fornece uma medida direta do desempenho do modelo em dados que não foram usados durante o treinamento, ajudando a verificar sua capacidade de generalização. No contexto do aprendizado federado, a avaliação é geralmente realizada de forma agregada após o treinamento federado ter sido concluído. A abordagem é diferente, pois a avaliação pode ser feita em vários conjuntos de dados de clientes para refletir a performance geral do modelo distribuído.

\section{Justificativa}

A escolha do processo de \textbf{Federated Averaging (FedAvg)} foi baseada em sua eficácia e simplicidade para a implementação de aprendizado federado em cenários onde a privacidade dos dados é uma preocupação central. A seguir, discutiremos as razões específicas para a escolha do FedAvg, suas vantagens e desvantagens, e os modelos de treinamento tradicionais que poderiam ser utilizados para comparar a performance.

\subsection{Razões para a Escolha do FedAvg}

O \textbf{FedAvg} é amplamente reconhecido e utilizado como uma das abordagens mais eficientes para o aprendizado federado, especialmente em contextos onde os dados são distribuídos entre vários clientes (dispositivos) que possuem capacidade computacional limitada. Ele opera através da média ponderada dos pesos dos modelos treinados localmente em cada cliente. Algumas das principais razões para a escolha do FedAvg incluem:

1. Simplicidade de Implementação: O FedAvg é relativamente fácil de implementar, tanto em termos de código quanto em infraestrutura. Ele não requer modificações complexas no modelo original e é compatível com a maioria dos modelos de aprendizado de máquina.

2. Eficiência em Ambientes Heterogêneos: Em cenários onde os clientes possuem capacidades computacionais variadas e dados não IID (independentemente e identicamente distribuídos), o FedAvg tem se mostrado robusto e eficaz. Ele permite que cada cliente contribua de acordo com sua capacidade, o que é ideal para dispositivos com diferentes níveis de poder computacional e conectividade.

3. Privacidade Preservada: Como o FedAvg realiza o treinamento localmente nos dispositivos dos clientes e apenas os pesos dos modelos (não os dados) são enviados para o servidor central, ele ajuda a preservar a privacidade dos dados.

\subsection{Vantagens do FedAvg}

1. Escalabilidade: FedAvg é altamente escalável, sendo capaz de lidar com milhares de dispositivos clientes. A abordagem distribuída minimiza a necessidade de centralização de dados, reduzindo os gargalos associados ao processamento em larga escala.

2. Flexibilidade: FedAvg pode ser aplicado a uma ampla variedade de modelos de aprendizado de máquina, desde redes neurais profundas até modelos mais simples, tornando-o versátil em diferentes cenários de aplicação.

3. Resiliência a Dados Não IID: Em muitos cenários do mundo real, os dados disponíveis em diferentes dispositivos não seguem uma distribuição IID. O FedAvg consegue lidar razoavelmente bem com essas discrepâncias.

\subsection{Desvantagens do FedAvg}

1. Convergência Mais Lenta: Devido à natureza distribuída e à variabilidade entre os dispositivos, a convergência do FedAvg pode ser mais lenta comparada a métodos centralizados, especialmente em casos onde os dados são altamente desbalanceados entre os clientes.

2. Dependência de Conectividade: O FedAvg requer que os dispositivos clientes enviem periodicamente seus modelos atualizados ao servidor central. Em ambientes com conectividade de rede instável ou dispositivos com pouca energia, isso pode se tornar um desafio.

3. Sobrecarga Computacional e de Comunicação: Embora o FedAvg minimize a necessidade de centralização de dados, ele ainda requer que os dispositivos locais realizem computações significativas e participem regularmente da comunicação com o servidor, o que pode ser oneroso para dispositivos de baixa potência.

\section{Código e aplicação dos modelos}

Esta seção apresenta o código completo desenvolvido para a implementação do modelo de aprendizado federado utilizando o TensorFlow Federated.

A segunda parte dessa seção apresenta a implementação do modelo de treinamento centralizado que será utilizado para comparação com o modelo federado. O código é estruturado de forma semelhante ao modelo federado, mas com a diferença de que os dados são centralizados em um único servidor para treinamento.

\subsection{Implementação completa do Modelo de Aprendizado Federado}

Esse código implementa um modelo de aprendizado federado usando o TensorFlow Federated (TFF). Primeiro, ele define um modelo de rede neural convolucional (CNN) usando o Keras, que é então convertido em um modelo federado utilizando a API do TFF. O processo de agregação federada é configurado com o algoritmo de "FedAvg" (Federação de Média Ponderada), que otimiza o modelo com o otimizador SGD tanto no cliente quanto no servidor. Os dados de treinamento do MNIST são divididos em subconjuntos para simular dados distribuídos em vários clientes. Em seguida, o treinamento é realizado por 10 rodadas, e as métricas como Acuracia, Acuracia top-3 e perda são coletadas em cada rodada. Ao final, são gerados gráficos que mostram a evolução dessas métricas ao longo das rodadas de treinamento federado.

\begin{lstlisting}
    import tensorflow as tf
    import tensorflow_federated as tff
    import matplotlib.pyplot as plt
    import time

    def create_keras_model():
        model = tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28, 1)),
            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])
        return model

    def create_federated_model():
        keras_model = create_keras_model()

        return tff.learning.models.from_keras_model(
            keras_model,
            input_spec=(tf.TensorSpec(shape=[None, 28, 28, 1], 
                        dtype=tf.float32),
                        tf.TensorSpec(shape=[None], dtype=tf.int64)),
            loss=tf.keras.losses.SparseCategoricalCrossentropy(),
            metrics=[
                tf.keras.metrics.SparseCategoricalAccuracy(),
                tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)
            ]
        )

    def build_federated_averaging_process():
        return tff.learning.algorithms.build_unweighted_fed_avg(
            model_fn=create_federated_model,
            client_optimizer_fn=lambda: 
                tf.keras.optimizers.SGD(learning_rate=0.02),
            server_optimizer_fn=lambda: 
                tf.keras.optimizers.SGD(learning_rate=1.0)
        )

    def preprocess(dataset):
        return dataset.map(lambda x, y: 
            (tf.cast(tf.expand_dims(x, -1), tf.float32), 
            tf.cast(y, tf.int64))).batch(20).repeat(10)

    def create_client_data(images, labels, num_clients=10, 
        num_samples_per_client=6000):
            client_data = []
            for i in range(num_clients):
                client_images = images[i*num_samples_per_client:
                    (i+1)*num_samples_per_client]
                client_labels = labels[i*num_samples_per_client:
                    (i+1)*num_samples_per_client]
                dataset = tf.data.Dataset.from_tensor_slices(
                    (client_images, client_labels))
                client_data.append(dataset)
        return client_data

    (mnist_train_images, mnist_train_labels), 
    (mnist_test_images, mnist_test_labels) = 
        tf.keras.datasets.mnist.load_data()
    
    mnist_train_images = mnist_train_images / 255.0
    mnist_test_images = mnist_test_images / 255.0

    federated_train_data = [preprocess(data) for data in 
        create_client_data(mnist_train_images, mnist_train_labels)]
    federated_test_data = [preprocess(data) for data in 
        create_client_data(mnist_test_images, mnist_test_labels)]

    iterative_process = build_federated_averaging_process()

    state = iterative_process.initialize()

    accuracy_per_round = []
    top_k_accuracy_per_round = []
    loss_per_round = []

    start_time = time.time()

    print('Rodando treinamento federado...')
    for round_num in range(1, 11):
        state, metrics = 
            iterative_process.next(state, federated_train_data)
        print(f'Rodada {round_num}: {metrics}')

        accuracy_per_round.append(metrics
            ['client_work']['train']
            ['sparse_categorical_accuracy'])
        
        top_k_accuracy_per_round.append(metrics
            ['client_work']['train']
            ['sparse_top_k_categorical_accuracy'])
        
        loss_per_round.append(metrics['client_work']
            ['train']['loss'])

    end_time = time.time()
    total_training_time = end_time - start_time
    print(f'Tempo total de treinamento: 
        {total_training_time:.2f} segundos')

    plt.figure(figsize=(10, 6))
    plt.plot(range(1, 11), 
        accuracy_per_round, marker='o', 
        linestyle='-', color='b', label='Acuracia')
    plt.title('Acuracia por Rodada de Treinamento Federado')
    plt.xlabel('Rodada')
    plt.ylabel('Acuracia')
    plt.grid(True)
    plt.legend()
    plt.show()

    plt.figure(figsize=(10, 6))
    plt.plot(range(1, 11), top_k_accuracy_per_round, 
        marker='o', linestyle='-', 
        color='g', label='Acuracia Top-3')
    plt.title('Acuracia Top-3 por Rodada de Treinamento Federado')
    plt.xlabel('Rodada')
    plt.ylabel('Acuracia Top-3')
    plt.grid(True)
    plt.legend()
    plt.show()

    plt.figure(figsize=(10, 6))
    plt.plot(range(1, 11), loss_per_round, 
        marker='o', linestyle='-', 
        color='r', label='Perda')
    plt.title('Perda por Rodada de Treinamento Federado')
    plt.xlabel('Rodada')
    plt.ylabel('Perda')
    plt.grid(True)
    plt.legend()
    plt.show()
\end{lstlisting}

\subsection{Implementação completa do Modelo de Aprendizado Centralizado - CNN}

Esse código implementa e treina um modelo de rede neural convolucional (CNN) em dados do MNIST usando TensorFlow. O modelo possui duas camadas convolucionais seguidas por camadas de pooling e uma camada densa totalmente conectada. Após a normalização dos dados de entrada (dividindo por 255), o modelo é compilado usando o otimizador Adam e a função de perda de entropia cruzada categórica esparsa.

Em seguida, o modelo é treinado por 5 Epocas com um batch size de 32, e o tempo total de treinamento é calculado. Após o treinamento, o modelo é avaliado nos dados de teste, e a precisão final é impressa. O código também gera dois gráficos: um que mostra a evolução da Acuracia e outro que mostra a perda durante o treinamento e a Validacao.

\begin{lstlisting}
    import tensorflow as tf
    import matplotlib.pyplot as plt
    import time

    def create_cnn_model():
        return tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28, 1)),
            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])

    (mnist_train, mnist_train_labels), 
    (mnist_test, mnist_test_labels) = 
        tf.keras.datasets.mnist.load_data()
    
    mnist_train = mnist_train / 255.0
    mnist_test = mnist_test / 255.0
    mnist_train = mnist_train[..., tf.newaxis].astype('float32')
    mnist_test = mnist_test[..., tf.newaxis].astype('float32')

    model_cnn = create_cnn_model()

    model_cnn.compile(optimizer='adam',
                    loss='sparse_categorical_crossentropy',
                    metrics=['accuracy'])

    start_time = time.time()

    history_cnn = 
        model_cnn.fit(mnist_train, mnist_train_labels,
                        epochs=5, batch_size=32,
                        validation_data=
                            (mnist_test, mnist_test_labels))

    end_time = time.time()
    total_time_cnn = end_time - start_time
    
    print(f'\nTempo total de treinamento (CNN): 
        {total_time_cnn:.2f} segundos')

    test_loss_cnn, test_acc_cnn = 
        model_cnn.evaluate(mnist_test, mnist_test_labels)
    print(f'\nPrecisao do modelo CNN nos dados de teste: 
        {test_acc_cnn}')

    plt.figure(figsize=(10, 5))
    plt.plot(history_cnn.history['accuracy'], 
        label='Acuracia de Treinamento (CNN)')
    plt.plot(history_cnn.history['val_accuracy'], 
        label='Acuracia de Validacao (CNN)')
    plt.title('Acuracia durante o Treinamento e Validacao (CNN)')
    plt.xlabel('Epocas')
    plt.ylabel('Acuracia')
    plt.legend()
    plt.grid(True)
    plt.show()

    plt.figure(figsize=(10, 5))
    plt.plot(history_cnn.history['loss'], 
        label='Perda de Treinamento (CNN)')
    plt.plot(history_cnn.history['val_loss'], 
        label='Perda de Validacao (CNN)')
    plt.title('Perda durante o Treinamento e Validacao (CNN)')
    plt.xlabel('Epocas')
    plt.ylabel('Perda')
    plt.legend()
    plt.grid(True)
    plt.show()
\end{lstlisting}

\subsection{Implementação completa do Modelo de Aprendizado Centralizado - DNN}

O  código a seguir define, treina e avalia um modelo de rede neural profunda (DNN) para a classificação de dígitos do MNIST. O modelo DNN é construído com cinco camadas densas, começando com uma camada de entrada que achata a entrada 28x28 pixels para um vetor unidimensional, seguido por camadas densas com 1024, 512, 256 e 128 neurônios, respectivamente, e uma camada de saída com 10 neurônios, correspondente às 10 classes de dígitos, usando a função de ativação softmax.

Após definir o modelo, ele é compilado usando o otimizador Adam e a função de perda \texttt{sparse\_categorical\_crossentropy}. O treinamento é realizado por 5 épocas com um tamanho de batch de 32. O tempo total de treinamento é calculado e impresso. O modelo é então avaliado nos dados de teste para obter a precisão. Os gráficos mostram a evolução da acurácia e da perda durante o treinamento e validação, fornecendo uma visão visual do desempenho do modelo ao longo das épocas.


\begin{lstlisting}
    import tensorflow as tf
    import matplotlib.pyplot as plt
    import time

    def create_dnn_model():
        return tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28, 1)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(1024, activation='relu'),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])

    model_dnn = create_dnn_model()

    model_dnn.compile(optimizer='adam',
                    loss='sparse_categorical_crossentropy',
                    metrics=['accuracy'])

    start_time = time.time()

    history_dnn = model_dnn.fit(mnist_train, mnist_train_labels,
                                epochs=5, batch_size=32,
                                validation_data=
                                    (mnist_test, mnist_test_labels))

    end_time = time.time()
    total_time_dnn = end_time - start_time
    print(f'\nTempo total de treinamento (DNN): 
        {total_time_dnn:.2f} segundos')

    test_loss_dnn, test_acc_dnn = 
        model_dnn.evaluate(mnist_test, mnist_test_labels)
    print(f'\nPrecisao do modelo DNN nos dados de teste: 
        {test_acc_dnn}')

    plt.figure(figsize=(10, 5))
    plt.plot(history_dnn.history['accuracy'], 
        label='Acuracia de Treinamento (DNN)')
    plt.plot(history_dnn.history['val_accuracy'], 
        label='Acuracia de Validacao (DNN)')
    plt.title('Acuracia durante o Treinamento e Validacao (DNN)')
    plt.xlabel('Epocas')
    plt.ylabel('Acuracia')
    plt.legend()
    plt.grid(True)
    plt.show()

    plt.figure(figsize=(10, 5))
    plt.plot(history_dnn.history['loss'], 
        label='Perda de Treinamento (DNN)')
    plt.plot(history_dnn.history['val_loss'], 
        label='Perda de Validacao (DNN)')
    plt.title('Perda durante o Treinamento e Validacao (DNN)')
    plt.xlabel('Epocas')
    plt.ylabel('Perda')
    plt.legend()
    plt.grid(True)
    plt.show()
\end{lstlisting}
    

\subsection{Implementação completa do Modelo de Aprendizado Centralizado - MLP}

Esse código implementa e treina um modelo de rede neural multicamada para a classificação do conjunto de dados MNIST. O modelo é composto por quatro camadas densas (fully connected), com funções de ativação ReLU nas três primeiras e softmax na camada de saída, que possui 10 neurônios, correspondendo às classes de dígitos do MNIST.

Os dados de entrada são achatados de uma matriz de 28x28 para um vetor de 784 elementos, uma exigência para redes MLP. O modelo é compilado usando o otimizador Adam e a função de perda de entropia cruzada categórica esparsa. Após o treinamento de 5 Epocas, o tempo total de treinamento é calculado e impresso. O modelo também é avaliado em dados de teste, e as métricas de Acuracia e perda são plotadas em gráficos para visualizar o desempenho durante o treinamento e a Validacao.

\begin{lstlisting}
    import tensorflow as tf
    import matplotlib.pyplot as plt
    import time

    def create_mlp_model():
        return tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28 * 28,)),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])

    mnist_train_mlp = mnist_train.reshape(-1, 28 * 28)
    mnist_test_mlp = mnist_test.reshape(-1, 28 * 28)

    model_mlp = create_mlp_model()

    model_mlp.compile(optimizer='adam',
                    loss='sparse_categorical_crossentropy',
                    metrics=['accuracy'])

    start_time = time.time()

    history_mlp = 
        model_mlp.fit(mnist_train_mlp, mnist_train_labels,
                        epochs=5, batch_size=32,
                        validation_data=
                        (mnist_test_mlp, mnist_test_labels))

    end_time = time.time()
    total_time_mlp = end_time - start_time
    
    print(f'\nTempo total de treinamento (MLP): 
        {total_time_mlp:.2f} segundos')

    test_loss_mlp, test_acc_mlp = 
        model_mlp.evaluate(mnist_test_mlp, mnist_test_labels)
    
        print(f'\nPrecisao do modelo MLP nos dados de teste: 
        {test_acc_mlp}')

    plt.figure(figsize=(10, 5))
    plt.plot(history_mlp.history['accuracy'], 
        label='Acuracia de Treinamento (MLP)')
    plt.plot(history_mlp.history['val_accuracy'], 
        label='Acuracia de Validacao (MLP)')
    plt.title('Acuracia durante o Treinamento e Validacao (MLP)')
    plt.xlabel('Epocas')
    plt.ylabel('Acuracia')
    plt.legend()
    plt.grid(True)
    plt.show()

    plt.figure(figsize=(10, 5))
    plt.plot(history_mlp.history['loss'], 
        label='Perda de Treinamento (MLP)')
    plt.plot(history_mlp.history['val_loss'], 
        label='Perda de Validacao (MLP)')
    plt.title('Perda durante o Treinamento e Validacao (MLP)')
    plt.xlabel('Epocas')
    plt.ylabel('Perda')
    plt.legend()
    plt.grid(True)
    plt.show()
\end{lstlisting}