\chapter[Desenvolvimento dos modelos de treinamento]{Desenvolvimento dos modelos de treinamento}
\addcontentsline{toc}{chapter}{Desenvolvimento dos modelos de treinamento}
\label{chap:desenvolvimento}

O problema central que o modelo de aprendizado federado busca resolver reside na exposição potencial de dados sensíveis quando centralizados em um único servidor para treinamento de modelos de IA. Em vez de enviar os dados dos dispositivos para um servidor central, onde poderiam ser acessados ou comprometidos, o aprendizado federado propõe um paradigma descentralizado no qual os dispositivos realizam o treinamento localmente, compartilhando apenas os parâmetros do modelo (como pesos e gradientes) com o servidor central. Esta abordagem permite que os dispositivos colaborem no desenvolvimento de um modelo global sem nunca expor os dados locais. 

A estruturação do problema foi conduzida considerando-se um cenário prático, onde múltiplos dispositivos, cada um contendo dados não identicamente distribuídos (não-IID), contribuem para o treinamento de um modelo de classificação de imagens (utilizando o conjunto de dados Fashion-MNIST como referência). Este cenário foi escolhido por refletir uma situação comum em aplicações reais, onde dados como registros de saúde, preferências de usuários ou informações financeiras são distribuídos entre dispositivos pessoais e não podem ser compartilhados diretamente por questões de privacidade e conformidade com regulamentos como o GDPR. Assim, o método desenvolvido abrange a implementação de um modelo federado que deve ser capaz de aprender de maneira eficiente e precisa a partir de dados dispersos, preservando a privacidade, e enfrenta desafios como a heterogeneidade dos dispositivos, a variabilidade da conectividade de rede e a necessidade de garantir a convergência do modelo global. A escolha do aprendizado federado, mais especificamente do processo Federated Averaging (FedAvg), é justificada pela sua capacidade de operar eficientemente em ambientes com essas características, buscando balancear a necessidade de proteção dos dados com a performance do modelo treinado.

\section{Implementação do Modelo de Aprendizado Federado}

Para melhor entendimento, foi dividido em seções a implementação do código do modelo de aprendizado federado. Cada seção abordará uma etapa do desenvolvimento do modelo e por fim será apresentado o código completo.

\subsection{Definição do Modelo Keras}

O primeiro passo na implementação do modelo federado foi a criação de um modelo Keras básico, que servirá como base para o treinamento federado. O modelo foi projetado para a base de dados Fashion-MNIST, que contém imagens de roupas divididas em 10 classes. A estrutura escolhida para esse modelo é uma Convolutional Neural Network (CNN), que é ideal para processar imagens. A CNN foi configurada com duas camadas de convolução seguidas por camadas de pooling, um padrão comum em tarefas de classificação de imagens, pois essas camadas são muito eficazes na extração de características visuais. A última parte do modelo é uma camada densa com 128 neurônios e a camada de saída com 10 neurônios, correspondendo às classes da base de dados.

\begin{lstlisting}[language=Python, caption={Função para criar um modelo Keras}, label={lst:create_keras_model}]
    def create_keras_model():
        model = tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28, 1)),
            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])
        return model
\end{lstlisting}
    
A escolha de uma CNN foi feita devido ao seu ótimo desempenho em tarefas de visão computacional, como é o caso do Fashion-MNIST, onde características como bordas, texturas e padrões podem ser capturados e processados de forma eficiente pelas camadas convolucionais.

\subsection{Construção do Modelo Federado}

Uma escolha importante ao implementar um modelo federado é como serão avaliadas as métricas de desempenho. Além da acurácia tradicional (\textit{Sparse Categorical Accuracy}), foi adicionada a métrica de Acurácia \textit{Top-3} (\textit{Sparse Top-K Categorical Accuracy}), que avalia se a classe correta está entre as três previsões mais prováveis feitas pelo modelo. Essa escolha é interessante em contextos onde o erro de classificação é aceitável se a previsão correta estiver próxima do topo, o que pode ser útil em sistemas de recomendação ou em ambientes onde há muitas classes e as previsões precisam ser refinadas ao longo do tempo.

\begin{lstlisting}[language=Python, caption={Construção do modelo federado}, label={lst:build_federated_model}]
    def create_federated_model():
    keras_model = create_keras_model()

    return tff.learning.models.from_keras_model(
        keras_model,
        input_spec=(tf.TensorSpec(shape=[None, 28, 28, 1], 
                        dtype=tf.float32),
                    tf.TensorSpec(shape=[None], dtype=tf.int64)),
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        metrics=[
            tf.keras.metrics.SparseCategoricalAccuracy(),
            tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)
        ]
    )
\end{lstlisting}

Ao incluir essa métrica no modelo federado, a expectativa era observar uma melhora no desempenho geral ao lidar com a base de dados distribuída, onde as variabilidades dos dados entre os dispositivos podem dificultar a obtenção de acurácia elevada de imediato. A Acurácia Top-3 oferece uma margem para avaliar se o modelo está capturando informações corretas em um cenário mais flexível.

\subsection{Construção do Processo de Federado}

O processo federado foi implementado utilizando o algoritmo Federated Averaging, que combina os pesos atualizados de cada cliente em um servidor central, onde os modelos locais são treinados nos dados locais e suas atualizações são agregadas. A escolha do Federated Averaging se deve à sua eficiência e simplicidade, especialmente ao lidar com grandes quantidades de dados distribuídos. Além disso, ele permite que os dispositivos participantes treinem seus modelos localmente e compartilhem apenas os gradientes ou atualizações dos pesos, preservando assim a privacidade dos dados dos usuários.

\begin{lstlisting}[language=Python, caption={Construção do processo federado}, label={lst:build_federated_process}]
    def build_federated_averaging_process():
        return tff.learning.algorithms.build_unweighted_fed_avg(
            model_fn=create_federated_model,
            client_optimizer_fn=lambda: 
                tf.keras.optimizers.Adam(learning_rate=0.001),
            server_optimizer_fn=lambda: 
                tf.keras.optimizers.SGD(learning_rate=1.0)
    )
\end{lstlisting}

Foi utilizado o otimizador Adam nos dispositivos locais, uma escolha feita para lidar melhor com as variações nos dados entre diferentes dispositivos, já que o Adam tem uma capacidade adaptativa de ajustar a taxa de aprendizado com base nas características dos dados. O otimizador SGD foi usado no servidor para combinar as atualizações dos modelos, garantindo uma convergência mais estável.

\subsection{Preparação dos Dados}

A etapa de preparação dos dados é crítica em um modelo federado. Aqui, os dados foram normalizados e divididos entre 10 clientes, simulando diferentes dispositivos locais. Essa divisão é importante para simular um ambiente federado realista, onde diferentes dispositivos possuem subconjuntos dos dados totais e, portanto, variabilidades nas distribuições de dados.

\begin{lstlisting}[language=Python, caption={Preparação dos dados}, label={lst:data_preparation}]
    def preprocess(dataset):
        return dataset.map(lambda x, y: 
            (tf.cast(tf.expand_dims(x, -1), tf.float32), 
             tf.cast(y, tf.int64))).batch(20)

    def create_client_data(images, labels, num_clients=10, 
            num_samples_per_client=6000):
        client_data = []
        for i in range(num_clients):
            client_images = 
                images[i*num_samples_per_client:(i+1)*
                        num_samples_per_client]
            client_labels = 
                labels[i*num_samples_per_client:(i+1)*
                        num_samples_per_client]
            dataset = 
                tf.data.Dataset.from_tensor_slices(
                    (client_images, client_labels))

            client_data.append(preprocess(dataset))
        return client_data
\end{lstlisting}

A escolha da base de dados Fashion-MNIST foi feita pela simplicidade e familiaridade desse conjunto no treinamento de modelos de classificação de imagens. Ele oferece um bom balanço entre complexidade visual e tamanho, sendo leve o suficiente para ser usado em dispositivos locais sem grandes recursos computacionais.

\subsection{Treinamento do Modelo Federado}

\begin{lstlisting}[language=Python, caption={Treinamento do modelo federado}, label={lst:federated_training}]
    iterative_process = build_federated_averaging_process()
    state = iterative_process.initialize()

    for round_num in range(1, 21):
        state, metrics = 
            iterative_process.next(state, federated_train_data)
        print(f'Rodada {round_num}: {metrics}')
\end{lstlisting}

O treinamento é executado através de um processo iterativo, onde o modelo é treinado em múltiplas rodadas. A escolha de 20 rodadas de treinamento permite uma observação inicial do comportamento do modelo federado sem sobrecarregar o sistema. Em cada rodada, os clientes locais treinam o modelo com seus dados privados e enviam as atualizações para o servidor central, onde as atualizações são agregadas para formar um modelo global atualizado. O uso da função \texttt{next} no TensorFlow Federated aplica a agregação de \textit{FedAvg}, onde as médias das atualizações dos clientes são calculadas. O feedback das métricas de cada rodada permite acompanhar a evolução do modelo, especialmente em termos de precisão (via \textit{SparseCategoricalAccuracy}), oferecendo uma visão clara de como o modelo está se ajustando aos dados federados ao longo do tempo.

\section{Implementação do Modelo de Aprendizado Centralizado}

Para criar um modelo de treinamento centralizado, foi realizado um processo semelhante ao do aprendizado federado utilizando a mesma biblioteca de dados (MNIST) e as mesmas ferramentas, apenas sem a distribuição de dados entre dispositivos. Esse modelo será utilizado para comparação com o modelo federado desenvolvido anteriormente, possibilitando a avaliação do impacto do aprendizado centralizado versus o aprendizado federado na preservação da privacidade e desempenho.

\subsection{Criação do Modelo de Aprendizado Centralizado - CNN}

Neste projeto foram implementados 3 modelos de treinamento centralizado, sendo que cada um deles utiliza uma técnica de treinamento sendo elas: uma Rede Neural Convolucional (CNN), uma Rede Neural Recorrente (RNN) e um modelo Rede neural multicamadas (MLP). A seguir, será apresentado o código referente à implementação do modelo de CNN centralizado afim de ilustrar como funciona o treinamento centralizado. Ao final do capítulo, será apresentado o código completo dos 3 modelos com uma breve explicação de cada um.

\subsubsection{Definição do Modelo Keras}

A arquitetura da rede convolucional é simples, composta por duas camadas convolucionais seguidas de camadas de pooling, o que é uma escolha típica para reconhecimento de imagens. A primeira camada convolucional usa 32 filtros, e a segunda utiliza 64 filtros, mantendo o modelo relativamente leve. Isso é importante considerando o uso de recursos limitados no Google Colab, onde o tempo de treinamento e a capacidade de processamento são fatores críticos. O uso de camadas de pooling reduz a dimensionalidade dos dados, diminuindo o número de parâmetros e o tempo de computação necessário.

\begin{lstlisting}[language=Python, caption={Definição do modelo Keras centralizado}, label={lst:centralized_keras_model}]
    def create_cnn_model():
        return tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28, 1)),
            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(10, activation='softmax')
        ])
\end{lstlisting}

O uso de dropout com uma taxa de 0.5 na camada totalmente conectada foi implementado para evitar overfitting, uma vez que o dataset Fashion-MNIST é relativamente pequeno, e sem técnicas de regularização, o modelo poderia memorizar os dados de treino, reduzindo sua capacidade de generalizar. O dropout desativa aleatoriamente 50\% dos neurônios durante o treinamento, o que força o modelo a aprender representações mais robustas dos dados, melhorando seu desempenho nos dados de validação.

\subsubsection{Criação e Compilação do Modelo Centralizado}

A função de perda escolhida foi a entropia cruzada esparsa (sparse\_categorical\_crossentropy), adequada para problemas de classificação multiclasse. Ela mede a diferença entre as previsões do modelo e as classes verdadeiras, penalizando mais fortemente previsões incorretas para classes que têm maior probabilidade atribuída. O otimizador Adam foi escolhido por ser um método de otimização robusto que combina as vantagens do RMSProp e do SGD com momentum, ajustando a taxa de aprendizado dinamicamente durante o treinamento. A taxa de aprendizado inicial foi ajustada para 0.001, que é um valor conservador e permite que o modelo aprenda de forma mais gradual e estável.

\begin{lstlisting}[language=Python, caption={Criação e compilação do modelo centralizado}, label={lst:centralized_model}]
    model_cnn = create_cnn_model()
    model_cnn.compile(optimizer=
                tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
\end{lstlisting}

\subsubsection{Treinamento do Modelo Centralizado}

Durante o treinamento, a precisão foi monitorada tanto nos dados de treinamento quanto nos de validação. A escolha pela métrica de acurácia faz sentido, dado que o problema é de classificação e a acurácia mede diretamente a proporção de previsões corretas. Além disso, a função de perda também foi monitorada para garantir que o modelo não só esteja melhorando sua acurácia, mas também minimizando a entropia cruzada ao longo das épocas.

\begin{lstlisting}[language=Python, caption={Treinamento do modelo centralizado}, label={lst:centralized_training}]
    history_cnn = 
        model_cnn.fit(fashion_train, 
                fashion_train_labels,
                epochs=50,
                batch_size=32,
                validation_data=
                (fashion_test, fashion_test_labels))
\end{lstlisting}

No modelo federado, o treinamento é distribuído entre vários clientes e o processo de treinamento é coordenado centralmente. A atualização dos pesos é feita de maneira agregada, o que é uma abordagem fundamentalmente diferente da atualização direta utilizada no treinamento centralizado.

\subsubsection{Avaliação do Modelo}

\begin{lstlisting}[language=Python, caption={Avaliação do modelo centralizado}, label={lst:centralized_evaluation}]
    test_loss_cnn, test_acc_cnn = 
        model_cnn.evaluate(mnist_test, mnist_test_labels)
\end{lstlisting}

A avaliação do modelo é feita usando \texttt{model.evaluate()}, que calcula a perda e a precisão do modelo nos dados de teste. Isso fornece uma medida direta do desempenho do modelo em dados que não foram usados durante o treinamento, ajudando a verificar sua capacidade de generalização. No contexto do aprendizado federado, a avaliação é geralmente realizada de forma agregada após o treinamento federado ter sido concluído. A abordagem é diferente, pois a avaliação pode ser feita em vários conjuntos de dados de clientes para refletir a performance geral do modelo distribuído.

\section{Justificativa}

A escolha do processo de \textbf{Federated Averaging (FedAvg)} foi baseada em sua eficácia e simplicidade para a implementação de aprendizado federado em cenários onde a privacidade dos dados é uma preocupação central. A seguir, discutiremos as razões específicas para a escolha do FedAvg, suas vantagens e desvantagens, e os modelos de treinamento tradicionais que poderiam ser utilizados para comparar a performance.

\subsection{Razões para a Escolha do FedAvg}

O \textbf{FedAvg} é amplamente reconhecido e utilizado como uma das abordagens mais eficientes para o aprendizado federado, especialmente em contextos onde os dados são distribuídos entre vários clientes (dispositivos) que possuem capacidade computacional limitada. Ele opera através da média ponderada dos pesos dos modelos treinados localmente em cada cliente. Algumas das principais razões para a escolha do FedAvg incluem:

1. Simplicidade de Implementação: O FedAvg é relativamente fácil de implementar, tanto em termos de código quanto em infraestrutura. Ele não requer modificações complexas no modelo original e é compatível com a maioria dos modelos de aprendizado de máquina.

2. Eficiência em Ambientes Heterogêneos: Em cenários onde os clientes possuem capacidades computacionais variadas e dados não IID (independentemente e identicamente distribuídos), o FedAvg tem se mostrado robusto e eficaz. Ele permite que cada cliente contribua de acordo com sua capacidade, o que é ideal para dispositivos com diferentes níveis de poder computacional e conectividade.

3. Privacidade Preservada: Como o FedAvg realiza o treinamento localmente nos dispositivos dos clientes e apenas os pesos dos modelos (não os dados) são enviados para o servidor central, ele ajuda a preservar a privacidade dos dados.

\subsection{Vantagens do FedAvg}

1. Escalabilidade: FedAvg é altamente escalável, sendo capaz de lidar com milhares de dispositivos clientes. A abordagem distribuída minimiza a necessidade de centralização de dados, reduzindo os gargalos associados ao processamento em larga escala.

2. Flexibilidade: FedAvg pode ser aplicado a uma ampla variedade de modelos de aprendizado de máquina, desde redes neurais profundas até modelos mais simples, tornando-o versátil em diferentes cenários de aplicação.

3. Resiliência a Dados Não IID: Em muitos cenários do mundo real, os dados disponíveis em diferentes dispositivos não seguem uma distribuição IID. O FedAvg consegue lidar razoavelmente bem com essas discrepâncias.

\subsection{Desvantagens do FedAvg}

1. Convergência Mais Lenta: Devido à natureza distribuída e à variabilidade entre os dispositivos, a convergência do FedAvg pode ser mais lenta comparada a métodos centralizados, especialmente em casos onde os dados são altamente desbalanceados entre os clientes.

2. Dependência de Conectividade: O FedAvg requer que os dispositivos clientes enviem periodicamente seus modelos atualizados ao servidor central. Em ambientes com conectividade de rede instável ou dispositivos com pouca energia, isso pode se tornar um desafio.

3. Sobrecarga Computacional e de Comunicação: Embora o FedAvg minimize a necessidade de centralização de dados, ele ainda requer que os dispositivos locais realizem computações significativas e participem regularmente da comunicação com o servidor, o que pode ser oneroso para dispositivos de baixa potência.

\section{Código e aplicação dos modelos}

Esta seção apresenta o código completo desenvolvido para a implementação do modelo de aprendizado federado utilizando o TensorFlow Federated.

A segunda parte dessa seção apresenta a implementação do modelo de treinamento centralizado que será utilizado para comparação com o modelo federado. O código é estruturado de forma semelhante ao modelo federado, mas com a diferença de que os dados são centralizados em um único servidor para treinamento.

\subsection{Implementação completa do Modelo de Aprendizado Federado}

Este código implementa um modelo de aprendizado federado utilizando o \textit{TensorFlow Federated} (TFF). O processo começa com a criação de um modelo \textit{Keras} convolucional (CNN) para o dataset \textit{Fashion-MNIST}, que classifica imagens em 10 categorias de roupas e acessórios. A função \texttt{create\_federated\_model} transforma este modelo em uma arquitetura federada, que distribui o treinamento entre vários "clientes", preservando os dados locais. O modelo utiliza a acurácia categórica e a acurácia \textit{Top-3} como métricas, além da perda categórica esparsa.

Em seguida, o código constrói o processo federado utilizando o algoritmo \textit{FedAvg} (média federada), e as funções de otimizador são configuradas tanto para o servidor quanto para os clientes. Os dados do \textit{Fashion-MNIST} são processados e distribuídos entre 10 clientes, simulando diferentes fontes de dados.

Por fim, o código realiza o treinamento federado por 20 rodadas, coletando e armazenando métricas como a acurácia, a acurácia \textit{Top-3}, e a perda. O tempo total de treinamento é medido, e gráficos são gerados para visualizar a evolução das métricas ao longo das rodadas de treinamento, fornecendo insights sobre o desempenho do modelo federado.

\begin{lstlisting}
    import tensorflow as tf
    import tensorflow_federated as tff
    import matplotlib.pyplot as plt
    import time

    def create_keras_model():
        model = tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28, 1)),
            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])
        return model

    def create_federated_model():
        keras_model = create_keras_model()

        return tff.learning.models.from_keras_model(
            keras_model,
            input_spec=
                (tf.TensorSpec(shape=[None, 28, 28, 1], 
                    dtype=tf.float32),
                tf.TensorSpec(shape=[None], dtype=tf.int64)),
            loss=tf.keras.losses.SparseCategoricalCrossentropy(),
            metrics=[
                tf.keras.metrics.SparseCategoricalAccuracy(),
                tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)
            ]
        )

    def build_federated_averaging_process():
        return tff.learning.algorithms.build_unweighted_fed_avg(
            model_fn=create_federated_model,
            client_optimizer_fn=lambda: 
                tf.keras.optimizers.Adam(learning_rate=0.001),
            server_optimizer_fn=lambda: 
                tf.keras.optimizers.SGD(learning_rate=1.0)
        )

    def preprocess(dataset):
        return dataset.map(lambda x, y: 
            (tf.cast(tf.expand_dims(x, -1), tf.float32), 
                tf.cast(y, tf.int64))).batch(20)

    def create_client_data(images, labels, 
            num_clients=10, num_samples_per_client=6000):
        client_data = []
        for i in range(num_clients):
            client_images = 
                images[i*num_samples_per_client:(i+1)*
                    num_samples_per_client]
            client_labels = 
                labels[i*num_samples_per_client:(i+1)*
                    num_samples_per_client]
            dataset = 
                tf.data.Dataset.from_tensor_slices((client_images,
                    client_labels))
            client_data.append(preprocess(dataset))
        return client_data

    (fashion_train_images, fashion_train_labels),
    (fashion_test_images, fashion_test_labels) = 
        tf.keras.datasets.fashion_mnist.load_data()

    fashion_train_images = fashion_train_images / 255.0
    fashion_test_images = fashion_test_images / 255.0

    federated_train_data = 
        create_client_data(fashion_train_images, fashion_train_labels)
    federated_test_data = 
        preprocess(tf.data.Dataset.from_tensor_slices(
                (fashion_test_images, fashion_test_labels)))

    iterative_process = build_federated_averaging_process()

    state = iterative_process.initialize()

    accuracy_per_round = []
    top_k_accuracy_per_round = []
    loss_per_round = []

    start_time = time.time()

    print('Rodando treinamento federado...')
    for round_num in range(1, 21):
        state, metrics = 
            iterative_process.next(state, federated_train_data)
        print(f'Rodada {round_num}/20: {metrics}')

        accuracy_per_round.append(
            metrics['client_work']
                   ['train']
                   ['sparse_categorical_accuracy'])
        top_k_accuracy_per_round.append(
            metrics['client_work']
                   ['train']
                   ['sparse_top_k_categorical_accuracy'])
        loss_per_round.append(
            metrics['client_work']
                   ['train']
                   ['loss'])

    end_time = time.time()
    total_training_time = end_time - start_time
    print(f'Tempo total de treinamento: 
        {total_training_time:.2f} segundos')

    def plot_metrics(metric_values, metric_name, title, ylabel, color):
        plt.figure(figsize=(10, 6))
        plt.plot(range(1, len(metric_values) + 1), 
                metric_values, 
                marker='o', 
                linestyle='-', 
                color=color, 
                label=metric_name)
        plt.title(title)
        plt.xlabel('Rodada')
        plt.ylabel(ylabel)
        plt.grid(True)
        plt.legend()
        plt.show()

    plot_metrics(accuracy_per_round, 'Acuracia', 
        'Acuracia por Rodada de Treinamento Federado', 
        'Acuracia', 'b')
    plot_metrics(top_k_accuracy_per_round, 'Acuracia Top-3', 
        'Acuracia Top-3 por Rodada de Treinamento Federado', 
        'Acuracia Top-3', 'g')
    plot_metrics(loss_per_round, 'Perda', 
        'Perda por Rodada de Treinamento Federado', 
        'Perda', 'r')
\end{lstlisting}

\subsection{Implementação completa do Modelo de Aprendizado Centralizado - CNN}

O código implementa um modelo de rede neural convolucional (CNN) utilizando o \textit{TensorFlow} para o dataset \textit{Fashion-MNIST}, que contém imagens de roupas classificadas em 10 categorias. O processo começa carregando e normalizando os dados para valores entre 0 e 1. Em seguida, o código adiciona uma dimensão aos dados, necessária para que a CNN processe as imagens.

O modelo CNN é definido com várias camadas, incluindo duas camadas convolucionais com 32 e 64 filtros, respectivamente, cada uma seguida por uma camada de \textit{max pooling} para redução dimensional. Após as camadas convolucionais, há uma camada totalmente conectada (\textit{dense}) com 128 neurônios e uma função de ativação \textit{ReLU}. O \textit{dropout} é utilizado para prevenir \textit{overfitting}, e a última camada utiliza \textit{softmax} para classificar as 10 categorias.

O modelo é compilado usando o otimizador \textit{Adam} e a função de perda de \textit{entropia cruzada categórica esparsa}. O treinamento é realizado ao longo de 50 épocas com os dados de treinamento, e o modelo é avaliado nos dados de teste, fornecendo as métricas de acurácia e perda. Ao final, são plotados gráficos para visualizar a evolução da acurácia e da perda durante o treinamento e a validação.

Essas escolhas de arquitetura e parâmetros visam otimizar a capacidade de generalização do modelo sem \textit{overfitting}, ao mesmo tempo em que o modelo é suficientemente robusto para o conjunto de dados relativamente simples como o \textit{Fashion-MNIST}.

\begin{lstlisting}
    import tensorflow as tf
    import numpy as np
    import matplotlib.pyplot as plt
    import time

    (fashion_train, fashion_train_labels),
    (fashion_test, fashion_test_labels) = 
        tf.keras.datasets.fashion_mnist.load_data()

    fashion_train = fashion_train / 255.0
    fashion_test = fashion_test / 255.0

    fashion_train = fashion_train[..., np.newaxis]
    fashion_test = fashion_test[..., np.newaxis]

    def create_cnn_model():
        return tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28, 1)),
            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), 
                activation='relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(10, activation='softmax')
        ])

    model_cnn = create_cnn_model()

    model_cnn.compile(optimizer=
            tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy'])

    start_time = time.time()

    history_cnn = model_cnn.fit(fashion_train, 
                    fashion_train_labels,
                    epochs=50,  
                    batch_size=32,
                    validation_data=
                        (fashion_test, fashion_test_labels))

    end_time = time.time()
    total_time_cnn = end_time - start_time
    print(f'\nTempo total de treinamento (CNN): 
        {total_time_cnn:.2f} segundos')

    test_loss_cnn, test_acc_cnn = 
        model_cnn.evaluate(fashion_test, fashion_test_labels)
    print(f'\nPrecisao do modelo CNN 
        nos dados de teste: {test_acc_cnn}')

    def plot_metrics(history, metric_name, title, ylabel):
        plt.figure(figsize=(10, 5))
        plt.plot(history.history[metric_name], 
            label=f'{ylabel} de Treinamento (CNN)')
        plt.plot(history.history[f'val_{metric_name}'], 
            label=f'{ylabel} de Validacao (CNN)')
        plt.title(title)
        plt.xlabel('Epocas')
        plt.ylabel(ylabel)
        plt.xticks(np.arange(0, 
            len(history.history[metric_name]), step=1))
        plt.legend()
        plt.grid(True)
        plt.show()

    plot_metrics(history_cnn, 'accuracy', 
        'Acuracia durante o Treinamento e Validacao (CNN)', 
        'Acuracia')
    plot_metrics(history_cnn, 'loss', 
        'Perda durante o Treinamento e Validacao (CNN)', 
        'Perda')
\end{lstlisting}

\subsection{Implementação completa do Modelo de Aprendizado Centralizado - MLP}

Este código implementa um modelo de \textit{Perceptron Multicamadas} (MLP) utilizando a biblioteca \textit{TensorFlow} para o dataset \textit{Fashion-MNIST}. O código é estruturado em diversas etapas, começando pelo carregamento e normalização dos dados, que são dimensionados para o intervalo de 0 a 1, como forma de otimizar o processo de treinamento.

Após isso, os dados de entrada são remodelados em uma estrutura linear adequada para um MLP (removendo a dimensão do canal de cores e transformando cada imagem em um vetor unidimensional de 784 valores). Em seguida, o modelo MLP é definido com quatro camadas densas, sendo as três primeiras camadas com 512, 256 e 128 neurônios e ativação \textit{ReLU}, para introduzir não-linearidade, e uma última camada de 10 neurônios, utilizando \textit{softmax} para a classificação das imagens em uma das 10 categorias do \textit{Fashion-MNIST}. O \textit{dropout} é utilizado para regularização e prevenir \textit{overfitting}.

O modelo é compilado com o otimizador \textit{Adam} e a função de perda de \textit{entropia cruzada categórica esparsa}, que é ideal para problemas de classificação com múltiplas classes. O treinamento é realizado por 50 épocas, e as métricas de desempenho, como \textit{acurácia} e \textit{perda}, são monitoradas tanto nos dados de treinamento quanto de validação. Por fim, gráficos são gerados para visualizar a evolução da acurácia e da perda ao longo das épocas, oferecendo uma visão clara do comportamento do modelo durante o treinamento e validação.

Esse modelo MLP é uma alternativa mais simples em relação às redes convolucionais, focando em capturar padrões globais dos dados sem levar em conta a estrutura espacial das imagens, como fazem as CNNs.

\begin{lstlisting}
    import tensorflow as tf
    import numpy as np
    import matplotlib.pyplot as plt
    import time

    (fashion_train, fashion_train_labels), 
    (fashion_test, fashion_test_labels) = 
        tf.keras.datasets.fashion_mnist.load_data()

    fashion_train = fashion_train / 255.0
    fashion_test = fashion_test / 255.0

    fashion_train_mlp = 
        fashion_train.reshape(-1, 28 * 28)
    fashion_test_mlp = 
        fashion_test.reshape(-1, 28 * 28)

    def create_mlp_model():
        return tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28 * 28,)),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])

    model_mlp = create_mlp_model()

    model_mlp.compile(optimizer='adam',
                    loss='sparse_categorical_crossentropy',
                    metrics=['accuracy'])

    start_time = time.time()

    history_mlp = model_mlp.fit(fashion_train_mlp, 
                                fashion_train_labels,
                                epochs=50,  
                                batch_size=32,
                                validation_data=(fashion_test_mlp, 
                                    fashion_test_labels))

    end_time = time.time()
    total_time_mlp = end_time - start_time
    print(f'\nTempo total de treinamento (MLP): 
        {total_time_mlp:.2f} segundos')

    test_loss_mlp, test_acc_mlp = 
        model_mlp.evaluate(fashion_test_mlp, fashion_test_labels)
    print(f'\nPrecisao do modelo MLP 
            nos dados de teste: {test_acc_mlp}')

    def plot_metrics(history, metric_name, title, ylabel):
        plt.figure(figsize=(10, 5))
        plt.plot(history.history[metric_name], 
            label=f'{ylabel} de Treinamento (MLP)')
        plt.plot(history.history[f'val_{metric_name}'], 
            label=f'{ylabel} de Validacao (MLP)')
        plt.title(title)
        plt.xlabel('Epocas')
        plt.ylabel(ylabel)
        plt.xticks(np.arange(1, 
            len(history.history[metric_name])+1, step=1))
        plt.legend()
        plt.grid(True)
        plt.show()

    plot_metrics(history_mlp, 'accuracy', 
        'Acuracia durante o Treinamento e Validacao (MLP)', 
        'Acuracia')
    plot_metrics(history_mlp, 'loss', 
        'Perda durante o Treinamento e Validacao (MLP)', 
        'Perda')
\end{lstlisting}

\subsection{Implementação completa do Modelo de Aprendizado Centralizado - DNN}

Este código implementa um modelo de MLP profunda, simulando uma rede neural profunda (DNN) para classificar imagens do conjunto de dados \textit{Fashion-MNIST} utilizando o \textit{TensorFlow}. A base de dados é carregada e normalizada, com os valores dos pixels sendo ajustados entre 0 e 1 para melhorar o desempenho durante o treinamento. Diferente de uma CNN (rede neural convolucional), as imagens são diretamente achatadas em vetores unidimensionais com 784 pixels (28x28) antes de serem processadas pelas camadas densas da DNN.

O modelo implementado possui uma arquitetura com quatro camadas densas completamente conectadas (\textit{fully connected}). A primeira camada contém 1024 neurônios com ativação \textit{ReLU}, seguida de uma camada \textit{Dropout} para evitar o \textit{overfitting}. Em seguida, temos camadas de 512, 256, e 128 neurônios com ativação \textit{ReLU}, e a camada final contém 10 neurônios com ativação \textit{softmax} para a saída de classificação em 10 classes, correspondentes às diferentes categorias do \textit{Fashion-MNIST}.

O modelo é treinado usando o otimizador \textit{Adam} e a função de perda \textit{sparse\_categorical\_crossentropy}, apropriada para problemas de classificação com várias classes. O treinamento ocorre ao longo de 50 épocas, com monitoramento das métricas de \textit{acurácia} e \textit{perda} tanto no conjunto de treinamento quanto de validação, permitindo verificar a evolução e o ajuste do modelo. Ao final, as métricas são plotadas para oferecer uma visualização clara do desempenho do modelo ao longo do treinamento.

\begin{lstlisting}
    import tensorflow as tf
    import numpy as np
    import matplotlib.pyplot as plt
    import time

    (fashion_train, fashion_train_labels), 
    (fashion_test, fashion_test_labels) = 
        tf.keras.datasets.fashion_mnist.load_data()

    fashion_train = fashion_train / 255.0
    fashion_test = fashion_test / 255.0

    fashion_train = fashion_train[..., np.newaxis]
    fashion_test = fashion_test[..., np.newaxis]

    def create_dnn_model():
        return tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(28, 28, 1)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(1024, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(10, activation='softmax')
        ])

    model_dnn = create_dnn_model()

    model_dnn.compile(optimizer=
                    tf.keras.optimizers.Adam(learning_rate=0.001),
                    loss='sparse_categorical_crossentropy',
                    metrics=['accuracy'])

    start_time = time.time()

    history_dnn = model_dnn.fit(fashion_train, 
                                fashion_train_labels,
                                epochs=50,
                                batch_size=32,
                                validation_data=(fashion_test, 
                                    fashion_test_labels))

    end_time = time.time()
    total_time_dnn = end_time - start_time
    print(f'\nTempo total de treinamento (DNN): 
        {total_time_dnn:.2f} segundos')

    test_loss_dnn, test_acc_dnn = 
        model_dnn.evaluate(fashion_test, fashion_test_labels)
    print(f'\nPrecisao do modelo DNN 
        nos dados de teste: {test_acc_dnn}')

    def plot_metrics(history, metric_name, title, ylabel):
        plt.figure(figsize=(10, 5))
        plt.plot(history.history[metric_name], 
            label=f'{ylabel} de Treinamento (DNN)')
        plt.plot(history.history[f'val_{metric_name}'], 
            label=f'{ylabel} de Validacao (DNN)')
        plt.title(title)
        plt.xlabel('Epocas')
        plt.ylabel(ylabel)
        plt.xticks(np.arange(1, 
            len(history.history[metric_name]) + 1, step=1))
        plt.legend()
        plt.grid(True)
        plt.show()

    plot_metrics(history_dnn, 'accuracy', 
        'Acuracia durante o Treinamento e Validacao (DNN)', 
        'Acuracia')
    plot_metrics(history_dnn, 'loss', 
        'Perda durante o Treinamento e Validacao (DNN)', 
        'Perda')
\end{lstlisting}